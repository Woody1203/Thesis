\part{Introduction} \label{part:how is the conclusion}

\chapter{Background and Introduction}

% \section*{Dimension Reduction}

With the rapid development of information technology, many fields need to process a large amount of high-dimensional data. Therefore, more and more features need to be extracted from the data, which leads to larger and larger dimensions of the data. Because high-dimensional data contains a lot of redundant information and the correlation between data is hidden in high-dimensional space, considering raw data are often sparse as a consequence of the curse of dimensionality that lead to dimension disasters and Hughes phenomenon.\\

\noindent At present, data dimension reduction(DR) has become an important method for data mining, computer vision, machine learning, and pattern recognition to solve Hughes phenomenon and dimension disasters. The data DR method is based on the spectral analysis of a specific sample matrix, converts the data in the original high-dimensional space into a low-dimensional subspace, and reveals the essential distribution structure or pattern relationship of the data in the high-dimensional space through the data DR method. This not only reduces the time complexity of data processing and makes it easier to find data structure information, but also low-dimensional data representation easier to visualize.\\


\noindent The DR algorithms can be devided into two branches: Algorithms such as PCA and MDS seek to preserve the distance structure within the data whereas algorithms like t-SNE , Isomap, LargeVis, UMAP and Laplacian Eigenmaps favor the preservation of local distances over global distance.\\

\noindent This thesis focus on three SNE based DR algorithms: BH t-SNE, LargeVis and UMAP, research the characteristics of the algorithms in different real-world datasets and provide a way to assess the performance of the results thanks to neighborhood-based DR performance criteria \cite{ref4}.


